{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf8c7bf9",
   "metadata": {},
   "source": [
    "# Fullstack GPT: #5.0 ~ #5.8\n",
    "\n",
    "- [x] Implement an LCEL chain with a memory that uses one of the memory classes we learned about.\n",
    "- [x] The chain should take the title of a movie and reply with three emojis that represent the movie. (i.e \"Top Gun\" -> \"ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\". \"The Godfather\" -> \"ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ \").\n",
    "- [x] Provide examples to the chain using FewShotPromptTemplate or FewShotChatMessagePromptTemplate to make sure it always replies with three emojis.\n",
    "- [x] To check that the memory is working ask the chain about two movies and then in another cell ask the chain to tell you what is the movie you asked about first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66daabea",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"title\": \"Top Gun\", \n",
    "        \"answer\": \"ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"The Godfather\",\n",
    "        \"answer\": \"ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e8582c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ«â¤ï¸ğŸ­ğŸ¤ğŸ‘©â€ğŸ¤â›ª"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "def invoke_chain(title):\n",
    "    result = chain.invoke({\"title\": title})\n",
    "    memory.save_context({\"input\": title}, {\"output\": result.content})\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    temperature=0.3,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{title}\"),\n",
    "    (\"ai\", \"{answer}\")\n",
    "])\n",
    "\n",
    "fewshot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"take the title of a movie and reply with three emojis that represent the movie.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    fewshot_prompt,\n",
    "    (\"human\", \"{title}\")\n",
    "])\n",
    "\n",
    "chain = RunnablePassthrough.assign(history=load_memory) | final_prompt | llm\n",
    "invoke_chain(\"Chocolate\")\n",
    "invoke_chain(\"Sister Act\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c610765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie you asked about first is \"Chocolate.\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='The movie you asked about first is \"Chocolate.\"')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"title\": \"What is the movie i asked about first.\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
